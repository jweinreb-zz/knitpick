{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_dict = {'host': 'localhost',\n",
    "        'dbname': 'insight',\n",
    "        'user': os.getenv('PG_USER'),\n",
    "        'password': os.getenv('PG_PASSWORD')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg2.connect(**conn_dict) as conn, conn.cursor() as cur:\n",
    "    cur.execute('SELECT * FROM patterns3')\n",
    "    res = cur.fetchall()\n",
    "    cols = [desc[0] for desc in cur.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.DataFrame(res, columns=cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Feature Eng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'price'] = df.price.apply(lambda x: float(x) if pd.notnull(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'pubyear'] = df.published.apply(lambda x: x.year if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'buttoned_mod'] = df[['attribute_buttoned', 'attribute_buttonholes']].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features that appear frequently enough in patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_cols = [a for a in df.columns if a.startswith('attribute_')]\n",
    "att_df = df[attribute_cols].sum(axis=0).reset_index().sort_values(0, ascending=False)\n",
    "att_df.columns = ['attribute', 'pattern_count']\n",
    "att_df.loc[:, 'pattern_share'] = att_df.pattern_count / df.shape[0]\n",
    "# att_df[att_df.pattern_share >= 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needles that appear frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "needles_cols = [n for n in df.columns if n.startswith('needles_')]\n",
    "needle_df = df[needles_cols].sum(axis=0).reset_index().sort_values(0, ascending=False)\n",
    "needle_df.columns = ['needle_size', 'pattern_count']\n",
    "needle_df.loc[:, 'pattern_share'] = needle_df.pattern_count / df.shape[0]\n",
    "# needle_df[needle_df.patte rn_share >= 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = ['difficulty_average','num_photos']\n",
    "\n",
    "cat_cols = ['pattern_type','yarn_weight']\n",
    "\n",
    "\n",
    "attribute_cols = ['attribute_adult', #\n",
    "                  'attribute_female',#\n",
    "                  'attribute_worked_flat',#\n",
    "                  'attribute_worked_in_the_round',#\n",
    "                  'attribute_chart',#\n",
    "                  'attribute_bottom_up',#\n",
    "                  'attribute_one_piece',#\n",
    "                  'attribute_unisex',#\n",
    "                  'attribute_seamed',#\n",
    "                  'attribute_lace',#\n",
    "                  'attribute_teen',#\n",
    "                  'attribute_ribbed_ribbing',#\n",
    "                  'attribute_textured',#\n",
    "                  'attribute_cables',#\n",
    "                  'attribute_stripes_colorwork',#\n",
    "                  'attribute_top_down',#\n",
    "                  'attribute_child',#\n",
    "                  'attribute_long',#\n",
    "                  'attribute_stranded',#\n",
    "                  'attribute_baby',#\n",
    "                  'attribute_positive_ease',#\n",
    "                  'attribute_has_schematic',#\n",
    "                  'attribute_male',#\n",
    "                  'attribute_eyelets',#\n",
    "                  'attribute_toddler', #\n",
    "                  'attribute_fitted',#\n",
    "                  'attribute_short_rows',\n",
    "                  'buttoned_mod']\n",
    "\n",
    "needles_cols = ['needles_us_6',\n",
    "                'needles_us_7',\n",
    "                'needles_us_4',\n",
    "                'needles_us_8',\n",
    "                'needles_us_5',\n",
    "                'needles_us_3',\n",
    "                'needles_us_2h',\n",
    "                'needles_us_10',\n",
    "                'needles_us_9',\n",
    "                'needles_us_1h',\n",
    "                'needles_us_2',\n",
    "                'needles_us_1',\n",
    "                'needles_us_11',\n",
    "                'needles_us_10h',\n",
    "                'needles_us_13',\n",
    "                'needles_us_15',\n",
    "                'needles_us_0']\n",
    "\n",
    "bool_cols = needles_cols + attribute_cols\n",
    "\n",
    "for cat_col in cat_cols:\n",
    "    df.loc[:, cat_col] = df[cat_col].apply(lambda x: str(x))\n",
    "\n",
    "for num_col in numeric_cols:\n",
    "    df.loc[:, num_col] = df[num_col].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['price'] + bool_cols + numeric_cols + cat_cols].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    4.9\n",
       "2    6.0\n",
       "3    6.0\n",
       "4    0.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is 393467 rows and 49 cols\n",
      "48.7% of patterns are free\n"
     ]
    }
   ],
   "source": [
    "X = df[bool_cols + numeric_cols + cat_cols]\n",
    "y = df.price.apply(lambda x: int(x > 0))  # is item for sale (1) or free (0)\n",
    "\n",
    "print(f'Data is {X.shape[0]} rows and {X.shape[1]} cols')\n",
    "print(f'{np.round(100*np.mean(y), 2)}% of patterns are free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (314773, 49)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data shape: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Elastic Net Logistic to predict free or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype bool, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype bool, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.87 s, sys: 327 ms, total: 10.2 s\n",
      "Wall time: 5.22 s\n",
      "ElasticNet SGDClassifier regression score: 0.701934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/pipeline.py:605: DataConversionWarning: Data with input dtype bool, float64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    }
   ],
   "source": [
    "cats = [list(set(X.pattern_type)),list(set(X.yarn_weight))]\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (StandardScaler(), numeric_cols + bool_cols),\n",
    "    (OneHotEncoder(categories=cats), cat_cols))\n",
    "\n",
    "sgd_params = dict(validation_fraction=0.1,\n",
    "                  penalty='elasticnet',\n",
    "                  loss='log',\n",
    "                  random_state=42,\n",
    "                  max_iter=10)\n",
    "\n",
    "pipeline = make_pipeline(preprocess, SGDClassifier(**sgd_params))\n",
    "\n",
    "%time pipeline.fit(X_train, y_train)\n",
    "print(\"ElasticNet SGDClassifier regression score: %f\" % pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get feature names and coefficients of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardscaler_features = preprocess.transformers_[0][2]\n",
    "ohe_features = [cat_cols[i] + '_' + item for i, l in enumerate(preprocess.transformers_[1][1].categories) for item in l]\n",
    "ftrs = standardscaler_features + ohe_features\n",
    "\n",
    "coefs = pipeline.named_steps['sgdclassifier'].coef_[0]\n",
    "model_results = pd.DataFrame({'feature': ftrs, 'coef': coefs}).sort_values('coef', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>pattern_type_mittens</td>\n",
       "      <td>0.357186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>yarn_weight_Cobweb</td>\n",
       "      <td>0.423011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>yarn_weight_Lace</td>\n",
       "      <td>0.447861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>yarn_weight_Fingering</td>\n",
       "      <td>0.512317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_photos</td>\n",
       "      <td>1.070976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature      coef\n",
       "70   pattern_type_mittens  0.357186\n",
       "74     yarn_weight_Cobweb  0.423011\n",
       "83       yarn_weight_Lace  0.447861\n",
       "86  yarn_weight_Fingering  0.512317\n",
       "1              num_photos  1.070976"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results[model_results.feature != 0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model F1 score: 0.6756098910217404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/pipeline.py:605: DataConversionWarning: Data with input dtype bool, float64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model F1 score: {f1_score(y_test, pipeline.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models to predict price for sale items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/pandas/core/indexing.py:480: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df2 = DF[(DF.currency == 'USD') & \\\n",
    "             (DF.price <= 17) & \\\n",
    "             (DF.price > 0) & \\\n",
    "             pd.notnull(DF.price)]\n",
    "\n",
    "df2.loc[:, 'buttoned_mod'] = df2[['attribute_buttoned', 'attribute_buttonholes']].max(axis=1)\n",
    "df2.loc[:, 'price'] = df2.price.apply(lambda x: float(x) if pd.notnull(x) else 0)\n",
    "df2.loc[:, 'projects_count'] = df2.projects_count.apply(lambda x: float(x) if pd.notnull(x) else 0)\n",
    "for cat_col in cat_cols:\n",
    "    df2.loc[:, cat_col] = df2[cat_col].apply(lambda x: str(x))\n",
    "\n",
    "for num_col in numeric_cols + ['projects_count']:\n",
    "    df2.loc[:, num_col] = df2[num_col].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[['projects_count']+ bool_cols + numeric_cols + cat_cols].dropna()\n",
    "y2 = df2.projects_count\n",
    "X2 = df2[bool_cols + numeric_cols + cat_cols]\n",
    "X2_train, X2_test, y2_train, y2_test = \\\n",
    "train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype bool, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/base.py:467: DataConversionWarning: Data with input dtype bool, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 375 ms, total: 1min 41s\n",
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('columntransformer', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True), ['difficulty_average', 'num_photos', 'needles_us_6', 'needles_us_...mators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = [list(set(X2.pattern_type)),list(set(X2.yarn_weight))]\n",
    "\n",
    "preprocess = make_column_transformer(\n",
    "    (StandardScaler(), numeric_cols + bool_cols),\n",
    "    (OneHotEncoder(categories=cats), cat_cols))\n",
    "\n",
    "rf_pipe = make_pipeline(preprocess, RandomForestRegressor(random_state=42, n_estimators=100))\n",
    "%time rf_pipe.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/pipeline.py:605: DataConversionWarning: Data with input dtype bool, float64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Test: 68.84973952945023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/sklearn/pipeline.py:605: DataConversionWarning: Data with input dtype bool, float64 were all converted to float64 by StandardScaler.\n",
      "  res = transformer.transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Test: 2.493833333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "print(f\"MSE Test: {np.sqrt(mean_squared_error(y2_train, rf_pipe.predict(X2_train)))}\")\n",
    "print(f\"MAE Test: {median_absolute_error(y2_test, rf_pipe.predict(X2_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard dev. of number of priojects: 164.64138433620136\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standard dev. of number of priojects: {np.std(df2.projects_count)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark: category means and medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/jason/anaconda3/envs/insight/lib/python3.7/site-packages/pandas/core/indexing.py:480: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "z = df2.groupby('pattern_type').agg({'projects_count': 'median'}).reset_index()\n",
    "median_map = dict(zip(z.pattern_type, z.projects_count))\n",
    "X2_test.loc[:, 'cat_mean'] = X2.pattern_type.apply(lambda x: median_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Median Abs error: {median_absolute_error(y2_test, X2_test.cat_mean)}\")\n",
    "print(f\"MSE: {np.sqrt(mean_squared_error(y2_test, X2_test.cat_mean))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
